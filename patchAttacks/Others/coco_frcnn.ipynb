{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/e34960/anaconda3/envs/patchdiff/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import PIL\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# from matplotlib import pyplot as plt \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
    "from diffusers import StableDiffusionInpaintPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data_folder = \"/homes/e34960/SegmentAndComplete/adv_data/coco_random_patch_100/data\"\n",
    "coco_files = os.listdir(coco_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = \"/project/trinity/datasets/APRICOT_ORIGINAL/Annotations/apricot_annotations_test.json\"\n",
    "\n",
    "with open(annotations_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "annotations_coco_91 = {}\n",
    "\n",
    "for i in range(len(data['categories'])):\n",
    "    annotations_coco_91[data['categories'][i]['id']] = data['categories'][i]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomImageMasks(n=1, scale=1.0, shape=(512,512)):\n",
    "    random_numbers = random.sample(range(0, len(coco_files)-1), n)\n",
    "\n",
    "    adv_imgs = []\n",
    "    orig_imgs = []\n",
    "    masks = []\n",
    "    all_bboxes = []\n",
    "    all_labels = []\n",
    "    for i in range(n):\n",
    "        img_info = torch.load(os.path.join(coco_data_folder, coco_files[random_numbers[i]]))\n",
    "        adv_img = np.squeeze(img_info['x_adv'])\n",
    "        # adv_img = (255.0 * adv_img).astype(np.uint8)\n",
    "        h, w, _ = adv_img.shape\n",
    "\n",
    "        # adv_img = cv2.resize(adv_img, (int(w * scale), int(h * scale)))\n",
    "        adv_img = cv2.resize(adv_img, shape)\n",
    "        adv_img = torch.from_numpy(np.transpose(adv_img, (2,0,1)))\n",
    "        adv_imgs.append(adv_img)\n",
    "\n",
    "        orig_img = np.squeeze(img_info['x'])\n",
    "        # orig_img = (255.0 * orig_img).astype(np.uint8)\n",
    "        h, w, _ = orig_img.shape\n",
    "\n",
    "        # orig_img = cv2.resize(orig_img, (int(w * scale), int(h * scale)))\n",
    "        orig_img = cv2.resize(orig_img, shape)\n",
    "        orig_img = torch.from_numpy(np.transpose(orig_img, (2,0,1)))\n",
    "        orig_imgs.append(orig_img)\n",
    "\n",
    "\n",
    "        mask = np.zeros((h, w))\n",
    "        mask[img_info['ymin']:img_info['ymin']+100, img_info['xmin']:img_info['xmin']+100] = 255\n",
    "        # mask = np.squeeze(img_info['Mask'])\n",
    "        # mask = (255.0 * mask).astype(np.uint8)\n",
    "\n",
    "        # # mask = cv2.resize(mask, (int(w * scale), int(h * scale)))\n",
    "        mask = cv2.resize(mask, shape)\n",
    "\n",
    "        # # Make a rectangular mask\n",
    "        # nonzero_indices = np.nonzero(mask)\n",
    "        # min_row = np.min(nonzero_indices[0])\n",
    "        # max_row = np.max(nonzero_indices[0])\n",
    "        # min_col = np.min(nonzero_indices[1])\n",
    "        # max_col = np.max(nonzero_indices[1])\n",
    "        # mask[min_row:max_row+1, min_col:max_col+1] = 255\n",
    "\n",
    "        masks.append(mask)\n",
    "\n",
    "\n",
    "        bounding_boxes = img_info['y']['boxes'].cpu().detach().numpy()\n",
    "        bboxes = np.reshape(bounding_boxes, (bounding_boxes.shape[1], bounding_boxes.shape[2]))        \n",
    "        bboxes[:, 2] = ((bboxes[:, 2] - bboxes[:, 0])*(shape[0]/w)).astype(int)\n",
    "        bboxes[:, 3] = ((bboxes[:, 3] - bboxes[:, 1])*(shape[1]/h)).astype(int)\n",
    "        bboxes[:, 0] = (shape[0] * bboxes[:, 0] / w).astype(int)\n",
    "        bboxes[:, 1] = (shape[1] * bboxes[:, 1] / h).astype(int)\n",
    "\n",
    "        all_bboxes.append(bboxes)\n",
    "\n",
    "        labels = img_info['y']['labels'].cpu().detach().numpy()\n",
    "        labels = np.reshape(labels, (labels.shape[1]))\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    return adv_imgs, orig_imgs, masks, all_bboxes, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-inpainting\", torch_dtype=torch.float16)\n",
    "pipe.to(\"cuda:2\")\n",
    "prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRepaintedImages(imgs, masks):\n",
    "    repainted_images = []\n",
    "    for i in range(len(imgs)):\n",
    "        img = (255.0 * np.transpose(imgs[i].numpy(), (1,2,0))).astype(np.uint8)\n",
    "        repainted_image = pipe(prompt=prompt, image=img, mask_image=masks[i]).images[0]\n",
    "        repainted_image = np.transpose(np.array(repainted_image), (2,0,1))\n",
    "        repainted_image = torch.from_numpy(repainted_image.astype(np.float32))\n",
    "        repainted_image /= 255.0\n",
    "        # repainted_image = repainted_image.double()\n",
    "        repainted_images.append(repainted_image)\n",
    "    \n",
    "    return repainted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.80it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.85it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.78it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.76it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.70it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.70it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.68it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.61it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.61it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.60it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.58it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.57it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.58it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.55it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.55it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.53it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.53it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.53it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.53it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.52it/s]\n"
     ]
    }
   ],
   "source": [
    "num_images = 20\n",
    "adv_imgs, orig_imgs, masks, all_bboxes, all_labels = getRandomImageMasks(n=num_images, scale=0.20, shape=(512,512))\n",
    "repainted_imgs = getRepaintedImages(adv_imgs, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "adv_predictions = model(adv_imgs)\n",
    "\n",
    "repaint_predictions = model(repainted_imgs)\n",
    "\n",
    "orig_predictions = model(orig_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_images):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(12, 20))\n",
    "\n",
    "    img = (255.0 * np.transpose(orig_imgs[i].numpy(), (1,2,0))).astype(np.uint8)\n",
    "\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('GT Bounding Boxes')\n",
    "\n",
    "    for j in range(all_bboxes[i].shape[0]):\n",
    "        if all_labels[i][j] != -10:\n",
    "            rectangle = patches.Rectangle((all_bboxes[i][j][0], all_bboxes[i][j][1]), all_bboxes[i][j][2], all_bboxes[i][j][3], linewidth=1, edgecolor='r', facecolor='none')\n",
    "            # cv2.putText(imgs[i], text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            axes[0].add_patch(rectangle)\n",
    "            axes[0].text(all_bboxes[i][j][0], all_bboxes[i][j][1], annotations_coco_91[all_labels[i][j]], fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "    \n",
    "\n",
    "    adv_img = (255.0 * np.transpose(adv_imgs[i].numpy(), (1,2,0))).astype(np.uint8)\n",
    "    adversarial_labels = adv_predictions[i]['labels'].detach().numpy()\n",
    "    adversarial_scores = adv_predictions[i]['scores'].detach().numpy()\n",
    "\n",
    "    adversarial_bboxes = copy.deepcopy(adv_predictions[i]['boxes'].detach().numpy())\n",
    "    adversarial_bboxes[:, 2] = (adversarial_bboxes[:, 2] - adversarial_bboxes[:, 0]).astype(int)\n",
    "    adversarial_bboxes[:, 3] = (adversarial_bboxes[:, 3] - adversarial_bboxes[:, 1]).astype(int)\n",
    "    adversarial_bboxes[:, 0] = (adversarial_bboxes[:, 0]).astype(int)\n",
    "    adversarial_bboxes[:, 1] = (adversarial_bboxes[:, 1]).astype(int)\n",
    "\n",
    "    axes[1].imshow(adv_img)\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Adversarial Bounding Boxes')\n",
    "    for j in range(adversarial_bboxes.shape[0]):\n",
    "        if adversarial_scores[j] > 0.5:\n",
    "            rectangle = patches.Rectangle((adversarial_bboxes[j][0], adversarial_bboxes[j][1]), adversarial_bboxes[j][2], adversarial_bboxes[j][3],linewidth=1, edgecolor='r', facecolor='none')\n",
    "            # cv2.putText(imgs[i], text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            axes[1].add_patch(rectangle)\n",
    "            axes[1].text(adversarial_bboxes[j][0], adversarial_bboxes[j][1], annotations_coco_91[adversarial_labels[j]], fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "\n",
    "\n",
    "    repaint_img = (255.0 * np.transpose(repainted_imgs[i].numpy(), (1,2,0))).astype(np.uint8)\n",
    "    repaint_labels = repaint_predictions[i]['labels'].detach().numpy()\n",
    "    repaint_scores = repaint_predictions[i]['scores'].detach().numpy()\n",
    "\n",
    "    repaint_bboxes = copy.deepcopy(repaint_predictions[i]['boxes'].detach().numpy())\n",
    "    repaint_bboxes[:, 2] = (repaint_bboxes[:, 2] - repaint_bboxes[:, 0]).astype(int)\n",
    "    repaint_bboxes[:, 3] = (repaint_bboxes[:, 3] - repaint_bboxes[:, 1]).astype(int)\n",
    "    repaint_bboxes[:, 0] = (repaint_bboxes[:, 0]).astype(int)\n",
    "    repaint_bboxes[:, 1] = (repaint_bboxes[:, 1]).astype(int)\n",
    "\n",
    "    axes[2].imshow(repaint_img)\n",
    "    axes[2].axis('off')\n",
    "    axes[2].set_title('Repainted Bounding Boxes')\n",
    "    for j in range(repaint_bboxes.shape[0]):\n",
    "        if repaint_scores[j] > 0.5:\n",
    "            rectangle = patches.Rectangle((repaint_bboxes[j][0], repaint_bboxes[j][1]), repaint_bboxes[j][2], repaint_bboxes[j][3],linewidth=1, edgecolor='r', facecolor='none')\n",
    "            # cv2.putText(imgs[i], text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            axes[2].add_patch(rectangle)\n",
    "            axes[2].text(repaint_bboxes[j][0], repaint_bboxes[j][1], annotations_coco_91[repaint_labels[j]], fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "\n",
    "\n",
    "    orig_img = (255.0 * np.transpose(orig_imgs[i].numpy(), (1,2,0))).astype(np.uint8)\n",
    "    orig_labels = orig_predictions[i]['labels'].detach().numpy()\n",
    "    orig_scores = orig_predictions[i]['scores'].detach().numpy()\n",
    "\n",
    "    orig_bboxes = copy.deepcopy(orig_predictions[i]['boxes'].detach().numpy())\n",
    "    orig_bboxes[:, 2] = (orig_bboxes[:, 2] - orig_bboxes[:, 0]).astype(int)\n",
    "    orig_bboxes[:, 3] = (orig_bboxes[:, 3] - orig_bboxes[:, 1]).astype(int)\n",
    "    orig_bboxes[:, 0] = (orig_bboxes[:, 0]).astype(int)\n",
    "    orig_bboxes[:, 1] = (orig_bboxes[:, 1]).astype(int)\n",
    "\n",
    "    axes[3].imshow(orig_img)\n",
    "    axes[3].axis('off')\n",
    "    axes[3].set_title('Vanilla Detector Bounding Boxes')\n",
    "    for j in range(orig_bboxes.shape[0]):\n",
    "        if orig_scores[j] > 0.5:\n",
    "            rectangle = patches.Rectangle((orig_bboxes[j][0], orig_bboxes[j][1]), orig_bboxes[j][2], orig_bboxes[j][3],linewidth=1, edgecolor='r', facecolor='none')\n",
    "            # cv2.putText(imgs[i], text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            axes[3].add_patch(rectangle)\n",
    "            axes[3].text(orig_bboxes[j][0], orig_bboxes[j][1], annotations_coco_91[orig_labels[j]], fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # display(fig)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
