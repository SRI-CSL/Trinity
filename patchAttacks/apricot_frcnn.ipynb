{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/e34960/anaconda3/envs/patchdiff/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import PIL\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# from matplotlib import pyplot as plt \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from PIL import Image\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
    "from diffusers import StableDiffusionInpaintPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apricot_dataset = \"/project/trinity/datasets/apricot/pub/apricot-mask/data_mask_v2\"\n",
    "apricot_files = os.listdir(apricot_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = \"/project/trinity/datasets/APRICOT_ORIGINAL/Annotations/apricot_annotations_test.json\"\n",
    "\n",
    "with open(annotations_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "annotations_coco_91 = {}\n",
    "\n",
    "for i in range(len(data['categories'])):\n",
    "    annotations_coco_91[data['categories'][i]['id']] = data['categories'][i]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomImageMasks(n=1, scale=1.0, shape=(512,512)):\n",
    "    random_numbers = random.sample(range(0, len(apricot_files)-1), n)\n",
    "\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    all_bboxes = []\n",
    "    all_labels = []\n",
    "    for i in range(n):\n",
    "        img_info = torch.load(os.path.join(apricot_dataset, apricot_files[random_numbers[i]]))\n",
    "        img = np.squeeze(img_info['Image'])\n",
    "        h, w, _ = img.shape\n",
    "        # img = (255.0 * img).astype(np.uint8)\n",
    "\n",
    "        # img = cv2.resize(img, (int(w * scale), int(h * scale)))\n",
    "        img = cv2.resize(img, shape)\n",
    "        img = torch.from_numpy(np.transpose(img, (2,0,1)))\n",
    "        imgs.append(img)\n",
    "\n",
    "        mask = np.squeeze(img_info['Mask'])\n",
    "        mask = (255.0 * mask).astype(np.uint8)\n",
    "\n",
    "        # mask = cv2.resize(mask, (int(w * scale), int(h * scale)))\n",
    "        mask = cv2.resize(mask, shape)\n",
    "\n",
    "        # Make a rectangular mask\n",
    "        nonzero_indices = np.nonzero(mask)\n",
    "        min_row = np.min(nonzero_indices[0])\n",
    "        max_row = np.max(nonzero_indices[0])\n",
    "        min_col = np.min(nonzero_indices[1])\n",
    "        max_col = np.max(nonzero_indices[1])\n",
    "        mask[min_row:max_row+1, min_col:max_col+1] = 255\n",
    "\n",
    "        masks.append(mask)\n",
    "\n",
    "\n",
    "        bounding_boxes = img_info['Annotations'][0]['boxes']\n",
    "        bboxes = np.reshape(bounding_boxes, (bounding_boxes.shape[1], bounding_boxes.shape[2]))        \n",
    "        bboxes[:, 2] = ((bboxes[:, 2] - bboxes[:, 0]) * img.shape[1]).astype(int)\n",
    "        bboxes[:, 3] = ((bboxes[:, 3] - bboxes[:, 1]) * img.shape[2]).astype(int)\n",
    "        bboxes[:, 0] = (img.shape[1] * bboxes[:, 0]).astype(int)\n",
    "        bboxes[:, 1] = (img.shape[2] * bboxes[:, 1]).astype(int)\n",
    "\n",
    "        all_bboxes.append(bboxes)\n",
    "\n",
    "        labels = img_info['Annotations'][0]['labels']\n",
    "        labels = np.reshape(labels, (labels.shape[1]))\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    return imgs, masks, all_bboxes, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-inpainting\", torch_dtype=torch.float16)\n",
    "pipe.to(\"cuda:2\")\n",
    "prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRepaintedImages(imgs, masks):\n",
    "    repainted_images = []\n",
    "    for i in range(len(imgs)):\n",
    "        img = (255.0 * np.transpose(imgs[i].numpy(), (1,2,0))).astype(np.uint8)\n",
    "        repainted_image = pipe(prompt=prompt, image=img, mask_image=masks[i]).images[0]\n",
    "        repainted_image = np.transpose(np.array(repainted_image), (2,0,1))\n",
    "        repainted_image = torch.from_numpy(repainted_image.astype(np.float32))\n",
    "        repainted_image /= 255.0\n",
    "        # repainted_image = repainted_image.double()\n",
    "        repainted_images.append(repainted_image)\n",
    "    \n",
    "    return repainted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.68it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.87it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.84it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.80it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.76it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.71it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.69it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.68it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.62it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.58it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.59it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.58it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.56it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.54it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.53it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.54it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.52it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.52it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.49it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.50it/s]\n"
     ]
    }
   ],
   "source": [
    "num_images = 20\n",
    "adv_imgs, masks, all_bboxes, all_labels = getRandomImageMasks(n=num_images, scale=0.20, shape=(512,512))\n",
    "repainted_imgs = getRepaintedImages(adv_imgs, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "adv_predictions = model(adv_imgs)\n",
    "\n",
    "repaint_predictions = model(repainted_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_images):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 20))\n",
    "    \n",
    "    ####### GT IMAGE WITH GT BOUNDING BOXES\n",
    "    img = (255.0 * np.transpose(adv_imgs[i].numpy(), (1,2,0))).astype(np.uint8)\n",
    "\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('GT Bounding Boxes')\n",
    "\n",
    "    for j in range(all_bboxes[i].shape[0]):\n",
    "        if all_labels[i][j] != -10:\n",
    "            rectangle = patches.Rectangle((all_bboxes[i][j][1], all_bboxes[i][j][0]), all_bboxes[i][j][3], all_bboxes[i][j][2], linewidth=1, edgecolor='r', facecolor='none')\n",
    "            # cv2.putText(imgs[i], text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            axes[0].add_patch(rectangle)\n",
    "            axes[0].text(all_bboxes[i][j][1], all_bboxes[i][j][0], annotations_coco_91[all_labels[i][j]], fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "\n",
    "    ########## ADVERSARIAL BOUNDING BOXES ###############\n",
    "\n",
    "    adversarial_bboxes = copy.deepcopy(adv_predictions[i]['boxes'].detach().numpy())\n",
    "    adversarial_bboxes[:, 2] = (adversarial_bboxes[:, 2] - adversarial_bboxes[:, 0]).astype(int)\n",
    "    adversarial_bboxes[:, 3] = (adversarial_bboxes[:, 3] - adversarial_bboxes[:, 1]).astype(int)\n",
    "    adversarial_bboxes[:, 0] = (adversarial_bboxes[:, 0]).astype(int)\n",
    "    adversarial_bboxes[:, 1] = (adversarial_bboxes[:, 1]).astype(int)\n",
    "\n",
    "    adversarial_labels = adv_predictions[i]['labels'].detach().numpy()\n",
    "    adversarial_scores = adv_predictions[i]['scores'].detach().numpy()\n",
    "\n",
    "    axes[1].imshow(img)\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Adversarial Bounding Boxes (FRCNN)')\n",
    "\n",
    "    for j in range(adversarial_bboxes.shape[0]):\n",
    "        if adversarial_scores[j] > 0.6:\n",
    "            rectangle = patches.Rectangle((adversarial_bboxes[j][0], adversarial_bboxes[j][1]), adversarial_bboxes[j][2], adversarial_bboxes[j][3],linewidth=1, edgecolor='r', facecolor='none')\n",
    "            # cv2.putText(imgs[i], text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            axes[1].add_patch(rectangle)\n",
    "            axes[1].text(adversarial_bboxes[j][0], adversarial_bboxes[j][1], annotations_coco_91[adversarial_labels[j]], fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "\n",
    "\n",
    "    ########## REPAINTED IMAGE BOUNDING BOXES ####################\n",
    "\n",
    "    repainted_img = (255.0 * np.transpose(repainted_imgs[i].numpy(), (1,2,0))).astype(np.uint8)\n",
    "\n",
    "    repainted_bboxes = copy.deepcopy(repaint_predictions[i]['boxes'].detach().numpy())\n",
    "\n",
    "    # print(repainted_bboxes)\n",
    "    repainted_bboxes[:, 2] = (repainted_bboxes[:, 2] - repainted_bboxes[:, 0]).astype(int)\n",
    "    repainted_bboxes[:, 3] = (repainted_bboxes[:, 3] - repainted_bboxes[:, 1]).astype(int)\n",
    "    repainted_bboxes[:, 0] = (repainted_bboxes[:, 0]).astype(int)\n",
    "    repainted_bboxes[:, 1] = (repainted_bboxes[:, 1]).astype(int)\n",
    "    # print(repainted_bboxes)\n",
    "\n",
    "    repaint_labels = repaint_predictions[i]['labels'].detach().numpy()\n",
    "    repaint_scores = repaint_predictions[i]['scores'].detach().numpy()\n",
    "\n",
    "    axes[2].imshow(repainted_img)\n",
    "    axes[2].axis('off')\n",
    "    axes[2].set_title('Repainted Bounding Boxes')\n",
    "\n",
    "    for j in range(repainted_bboxes.shape[0]):\n",
    "        if repaint_scores[j] > 0.5:\n",
    "            rectangle = patches.Rectangle((repainted_bboxes[j][0], repainted_bboxes[j][1]), repainted_bboxes[j][2], repainted_bboxes[j][3],linewidth=1, edgecolor='r', facecolor='none')\n",
    "            # cv2.putText(imgs[i], text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            axes[2].add_patch(rectangle)\n",
    "            axes[2].text(repainted_bboxes[j][0], repainted_bboxes[j][1], annotations_coco_91[repaint_labels[j]], fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # display(fig)\n",
    "    plt.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patchdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
