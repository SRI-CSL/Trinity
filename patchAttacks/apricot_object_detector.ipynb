{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/e34960/anaconda3/envs/patchdiff/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import PIL\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# from matplotlib import pyplot as plt \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "from PIL import Image\n",
    "import copy\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apricot_dataset = \"/project/trinity/datasets/apricot/pub/apricot-mask/data_mask_v2\"\n",
    "apricot_files = os.listdir(apricot_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = \"/project/trinity/datasets/APRICOT_ORIGINAL/Annotations/apricot_annotations_test.json\"\n",
    "\n",
    "with open(annotations_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "annotations_coco_91 = {}\n",
    "\n",
    "for i in range(len(data['categories'])):\n",
    "    annotations_coco_91[data['categories'][i]['id']] = data['categories'][i]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomImageMasks(n=1, scale=1.0, shape=(512,512)):\n",
    "    random_numbers = random.sample(range(0, len(apricot_files)-1), n)\n",
    "\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    all_bboxes = []\n",
    "    all_labels = []\n",
    "    for i in range(n):\n",
    "        img_info = torch.load(os.path.join(apricot_dataset, apricot_files[random_numbers[i]]))\n",
    "        img = np.squeeze(img_info['Image'])\n",
    "        img = (255.0 * img).astype(np.uint8)\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        # img = cv2.resize(img, (int(w * scale), int(h * scale)))\n",
    "        img = cv2.resize(img, shape)\n",
    "        imgs.append(img)\n",
    "\n",
    "        mask = np.squeeze(img_info['Mask'])\n",
    "        mask = (255.0 * mask).astype(np.uint8)\n",
    "\n",
    "        # mask = cv2.resize(mask, (int(w * scale), int(h * scale)))\n",
    "        mask = cv2.resize(mask, shape)\n",
    "\n",
    "        # Make a rectangular mask\n",
    "        nonzero_indices = np.nonzero(mask)\n",
    "        min_row = np.min(nonzero_indices[0])\n",
    "        max_row = np.max(nonzero_indices[0])\n",
    "        min_col = np.min(nonzero_indices[1])\n",
    "        max_col = np.max(nonzero_indices[1])\n",
    "        mask[min_row:max_row+1, min_col:max_col+1] = 255\n",
    "\n",
    "        masks.append(mask)\n",
    "\n",
    "\n",
    "        bounding_boxes = img_info['Annotations'][0]['boxes']\n",
    "        bboxes = np.reshape(bounding_boxes, (bounding_boxes.shape[1], bounding_boxes.shape[2]))        \n",
    "        bboxes[:, 2] = ((bboxes[:, 2] - bboxes[:, 0]) * img.shape[0]).astype(int)\n",
    "        bboxes[:, 3] = ((bboxes[:, 3] - bboxes[:, 1]) * img.shape[1]).astype(int)\n",
    "        bboxes[:, 0] = (img.shape[0] * bboxes[:, 0]).astype(int)\n",
    "        bboxes[:, 1] = (img.shape[1] * bboxes[:, 1]).astype(int)\n",
    "\n",
    "        all_bboxes.append(bboxes)\n",
    "\n",
    "        labels = img_info['Annotations'][0]['labels']\n",
    "        labels = np.reshape(labels, (labels.shape[1]))\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    return imgs, masks, all_bboxes, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-inpainting\", torch_dtype=torch.float16)\n",
    "pipe.to(\"cuda:2\")\n",
    "prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRepaintedImages(imgs, masks):\n",
    "    repainted_images = []\n",
    "    for i in range(len(imgs)):\n",
    "        repainted_image = pipe(prompt=prompt, image=imgs[i], mask_image=masks[i]).images[0]\n",
    "        repainted_images.append(repainted_image)\n",
    "    \n",
    "    return repainted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.81it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:04<00:00, 10.51it/s]\n"
     ]
    }
   ],
   "source": [
    "num_images = 20\n",
    "imgs, masks, all_bboxes, all_labels = getRandomImageMasks(n=num_images, scale=0.20, shape=(512,512))\n",
    "repainted_images = getRepaintedImages(imgs, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /homes/e34960/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-7-5 Python-3.9.16 torch-1.8.1+cu102 CUDA:0 (GeForce RTX 2080 Ti, 11019MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "adversarial_images = copy.deepcopy(imgs)\n",
    "adversarial_results = model(adversarial_images)\n",
    "\n",
    "repainted_results = model(repainted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_images):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 20))\n",
    "\n",
    "    axes[0].imshow(imgs[i])\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('GT Bounding Boxes')\n",
    "\n",
    "    for j in range(all_bboxes[i].shape[0]):\n",
    "        if all_labels[i][j] != -10:\n",
    "            rectangle = patches.Rectangle((all_bboxes[i][j][1], all_bboxes[i][j][0]), all_bboxes[i][j][3], all_bboxes[i][j][2], linewidth=1, edgecolor='r', facecolor='none')\n",
    "            # cv2.putText(imgs[i], text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            axes[0].add_patch(rectangle)\n",
    "            axes[0].text(all_bboxes[i][j][1], all_bboxes[i][j][0], annotations_coco_91[all_labels[i][j]], fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "    \n",
    "\n",
    "    adversarial_bboxes = (adversarial_results.pandas().xyxy[i]).to_numpy()\n",
    "    adversarial_bboxes[:, 2] = (adversarial_bboxes[:, 2] - adversarial_bboxes[:, 0]).astype(int)\n",
    "    adversarial_bboxes[:, 3] = (adversarial_bboxes[:, 3] - adversarial_bboxes[:, 1]).astype(int)\n",
    "    adversarial_bboxes[:, 0] = (adversarial_bboxes[:, 0]).astype(int)\n",
    "    adversarial_bboxes[:, 1] = (adversarial_bboxes[:, 1]).astype(int)\n",
    "\n",
    "    axes[1].imshow(imgs[i])\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Adversarial Bounding Boxes')\n",
    "    for j in range(adversarial_bboxes.shape[0]):\n",
    "        rectangle = patches.Rectangle((adversarial_bboxes[j][0], adversarial_bboxes[j][1]), adversarial_bboxes[j][2], adversarial_bboxes[j][3], linewidth=1, edgecolor='r', facecolor='none')\n",
    "        axes[1].add_patch(rectangle)\n",
    "        axes[1].text(adversarial_bboxes[j][0],  adversarial_bboxes[j][1]-10, \"{}:{:.2f}\".format(adversarial_bboxes[j][6], adversarial_bboxes[j][4]) , fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "\n",
    "    # print(imgs[i].shape)\n",
    "    # print(masks[i].shape)\n",
    "    repainted_bboxes = (repainted_results.pandas().xyxy[i]).to_numpy()\n",
    "    repainted_bboxes[:, 2] = (repainted_bboxes[:, 2] - repainted_bboxes[:, 0]).astype(int)\n",
    "    repainted_bboxes[:, 3] = (repainted_bboxes[:, 3] - repainted_bboxes[:, 1]).astype(int)\n",
    "    repainted_bboxes[:, 0] = (repainted_bboxes[:, 0]).astype(int)\n",
    "    repainted_bboxes[:, 1] = (repainted_bboxes[:, 1]).astype(int)\n",
    "\n",
    "    axes[2].imshow(repainted_images[i])\n",
    "    axes[2].axis('off')\n",
    "    axes[2].set_title('Repainted Bounding Boxes')\n",
    "    for j in range(repainted_bboxes.shape[0]):\n",
    "        rectangle = patches.Rectangle((repainted_bboxes[j][0], repainted_bboxes[j][1]), repainted_bboxes[j][2], repainted_bboxes[j][3], linewidth=1, edgecolor='r', facecolor='none')\n",
    "        axes[2].add_patch(rectangle)\n",
    "        axes[2].text(repainted_bboxes[j][0],  repainted_bboxes[j][1]-10, \"{}:{:.2f}\".format(repainted_bboxes[j][6], repainted_bboxes[j][4]) , fontsize=8, bbox=dict(facecolor='black', alpha=0.8, pad=1), color='white')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    display(fig)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
