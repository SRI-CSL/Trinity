{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9d2b241-dd31-413d-81b7-23bf6dab58c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_dir           = \"/WorkSpace-2/aroy/data/datasets/coco_ooc/OOC_images_selected/\"\n",
    "caption_dir       = \"/WorkSpace-2/aroy/data/datasets/coco_ooc/OOC_images_selected_captions/\"\n",
    "captions_filepath = '/WorkSpace-2/aroy/data/OOC/LLM/coco_ooc_captions.npy'\n",
    "\n",
    "os.makedirs(caption_dir, exist_ok=True)\n",
    "\n",
    "# hyperparameters\n",
    "max_new_tokens=20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782d88f5-5e86-42b2-b353-bee62b9f7e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-6.7b-coco\")\n",
    "# by default `from_pretrained` loads the weights in float32\n",
    "# we load in float16 instead to save memory\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16) \n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-6.7b-coco\", torch_dtype=torch.float16) \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f707a5db-fa93-4302-af5d-8c9c88c2b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_path_list = glob.glob(os.path.join(img_dir, '*.jpg'))\n",
    "image_name_list = ['']*len(image_path_list)\n",
    "caption_list    = ['']*len(image_path_list)\n",
    "\n",
    "for indx, image_path in enumerate(image_path_list):\n",
    "    \n",
    "    image_name = os.path.splitext(os.path.split(image_path)[1])[0]\n",
    "    image_name_list[indx] = image_name\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    inputs = processor(image, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()    \n",
    "    caption_list[indx] = caption\n",
    "    \n",
    "captions_dict = {'image_name_list': image_name_list, 'caption_list':caption_list}\n",
    "np.save(captions_filepath, captions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6e56ab-2c6b-41f0-8837-ccfe3a6a38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "455860aa-b2ff-40cf-aa59-6bcd5a4b8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "captions_filepath = '/WorkSpace-2/aroy/data/OOC/LLM/coco_ooc_captions.npy'\n",
    "captions_dict = np.load(captions_filepath, allow_pickle=True)\n",
    "captions_dict = captions_dict.item()\n",
    "\n",
    "image_name_list = captions_dict['image_name_list']\n",
    "caption_list    = captions_dict['caption_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3edb5591-8cc2-40fa-8cc1-8e3f5d68500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_val2014_000000004296_var1_512_0 : a zebra is standing in a room with a laptop on a table\n",
      "COCO_val2014_000000004296_var1_512_0 : a tennis players are playing a game on a blue court\n",
      "COCO_val2014_000000004296_var1_512_0 : a laptop computer sitting on a desk with a giraffe on it\n",
      "COCO_val2014_000000004296_var1_512_0 : two men riding horses on the beach with a suitcase in the background\n",
      "COCO_val2014_000000004296_var1_512_0 : a large sheep is standing in a living room with a table and chairs\n",
      "COCO_val2014_000000004296_var1_512_0 : a baseball game with a slice of pizza on the field\n",
      "COCO_val2014_000000004296_var1_512_0 : a baseball game with a batter, catcher, umpire and pitcher\n",
      "COCO_val2014_000000004296_var1_512_0 : a bird sitting on top of a kitchen counter in a remodeled kitchen\n"
     ]
    }
   ],
   "source": [
    "for img_name, caption in zip(image_name_list, caption_list):\n",
    "    print(image_name + ' : ' + caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe419fee-f405-47d6-95a6-65ba8612278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_string = \" - is this normal?\"\n",
    "gpt_response_list = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list[indx] = response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2f1f13-0809-4573-bebc-d0afc85e132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_string = \" - is this normal? yes or no\"\n",
    "gpt_response_list_YN = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list_YN[indx] = response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9392277-15ec-43ca-93d3-d354cbe8f32c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is not normal for a zebra to be standing in a room with a laptop on a table. The percentage of possibility is extremely low, probably less than 1%. Zebras are wild animals typically found in grasslands and savannas, not in human environments like rooms with technology.\\n',\n",
       " \"Yes, it is normal for tennis players to play a game on a blue court. Blue courts are quite common, particularly in hard court surfaces, such as those used in the Australian Open and the US Open. It's difficult to assign an exact percentage of possibility, but it is certainly a common occurrence in the world of tennis.\",\n",
       " \"It is not normal to see a laptop computer sitting on a desk with a giraffe on it. This could be interpreted as a small toy or figurine of a giraffe, which would be more plausible. However, if it's meant to be a real-life giraffe, that would be highly improbable. \\n\\nIn the case of a small toy or figurine: 75%\\nIn the case of a real-life giraffe: <1%\",\n",
       " \"It is not common to see two men riding horses on the beach with a suitcase in the background, but it's not impossible. The percentage of possibility is subjective and could vary based on location, culture, and personal experiences. In general, I would estimate a low percentage of possibility, maybe around 5-10%.\",\n",
       " \"It is not normal for a large sheep to be standing in a living room with a table and chairs. While it's difficult to assign an exact percentage to the possibility, it would be considered highly unlikely and out of the ordinary, so less than 1% possibility.\",\n",
       " 'No, it is not normal to have a slice of pizza on the field during a baseball game. The percentage of possibility is likely less than 1%, as it is highly unusual and against the rules to have foreign objects on the playing field during a game.',\n",
       " 'Yes, this is a normal scenario in a baseball game. The batter, catcher, umpire, and pitcher are all essential roles in the game. The percentage of possibility for this scenario to occur is close to 100% during a typical baseball game.',\n",
       " 'It is not normal for a bird to be sitting on top of a kitchen counter in a remodeled kitchen, as birds are generally not found inside homes, especially on kitchen counters. The percentage of possibility for this occurrence is relatively low, perhaps around 5-10%, depending on factors such as open windows or doors, the presence of pet birds, or if the house is located in an area with a high bird population.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = \" - is this normal? percentage of possibility\"\n",
    "gpt_response_list = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list[indx] = response\n",
    "    \n",
    "gpt_response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c28da24-850b-4ed2-b30b-69eedbdba6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I would say this is a 1 or 2 on a scale of 0 to 10, as it is highly unlikely but still within the realm of possibility if it were set up intentionally for entertainment or an art installation.',\n",
       " '7',\n",
       " 'I would say it is a 2. While it is possible to have a giraffe figurine or a giraffe sticker on a laptop, having an actual giraffe on a laptop is highly unlikely due to size and weight constraints.',\n",
       " \"I would say a 3, as it's not impossible but rather uncommon to see men riding horses on the beach with a suitcase in the background.\",\n",
       " '3',\n",
       " 'I would say a 2, as it is quite unlikely but not impossible that someone might accidentally drop a slice of pizza on the field.',\n",
       " '10',\n",
       " \"It is difficult to provide a precise number on the likelihood of this, as it depends on a number of factors such as whether the bird is a pet or managed to fly in accidentally, or if the kitchen is open to the outdoors in some way. I would say it's a 4 or 5 out of 10, as it's not completely unlikely but also not very common in most households.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = \" - how likely is this in a scale between 0 to 10\"\n",
    "\n",
    "gpt_response_list = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list[indx] = response\n",
    "    \n",
    "gpt_response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bee2da-4d4a-4f1c-97f3-85ba83508cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \" - whats is the most likely object that is out of context?\"\n",
    "\n",
    "gpt_response_list = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list[indx] = response\n",
    "    \n",
    "gpt_response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d30fa036-3e75-4a95-a796-f52fa33b13ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a man standing on a street corner talking on a cell phone\" - how normal is this in a scale between 0 to 10? The rating is:\n",
      "10\n",
      "----------------------------------------\n",
      "\"a horse pulling a small car down a road\" - how normal is this in a scale between 0 to 10? The rating is:\n",
      "3\n",
      "----------------------------------------\n",
      "\"a group of people standing around a bunk bed with a ladder\" - how normal is this in a scale between 0 to 10? The rating is:\n",
      "5\n",
      "----------------------------------------\n",
      "\"a red car parked on top of a roof next to a house\" - how normal is this in a scale between 0 to 10? The rating is:\n",
      "2\n",
      "----------------------------------------\n",
      "\"a plane that is in a cemetery with people walking by\" - how normal is this in a scale between 0 to 10? The rating is:\n",
      "2\n",
      "----------------------------------------\n",
      "\"a man walking down a street with a yellow machine on the road\" - how normal is this in a scale between 0 to 10? The rating is:\n",
      "5\n",
      "----------------------------------------\n",
      "\"a truck is stuck in a drive thru at a fast food restaurant\" - how normal is this in a scale between 0 to 10? The rating is:\n",
      "3\n",
      "----------------------------------------\n",
      "\"a car is in the front of a store that is on fire\" - how normal is this in a scale between 0 to 10? The rating is:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3972836/1398575565.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent_str\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m           \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         )\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrequest_timeout\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mTIMEOUT_SECS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_thread_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m             )\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Language model for query\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import openai\n",
    "import time\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# captions_filepath = \"/WorkSpace-2/aroy/data/OOC/COCO_OOC/blip2_caption/out_of_context_MIT_captions_opt-6.7b-coco.npy\"\n",
    "captions_filepath = \"/WorkSpace-2/aroy/data/OOC/COCO_OOC/blip2_caption/coco_val2014_captions_opt-6.7b-coco.npy\"\n",
    "response_dir      = \"/WorkSpace-2/aroy/data/OOC/COCO_OOC/LLM_OP/GPT-4/out_of_context_MIT/possible_0_10_gpt4_token_1000_num\"\n",
    "query_string = \" - how normal is this in a scale between 0 to 10? The rating is:\"\n",
    "\n",
    "start_indx = 0\n",
    "end_indx   = 30\n",
    "\n",
    "os.makedirs(response_dir, exist_ok=True)\n",
    "\n",
    "# load captions\n",
    "captions_dict = np.load(captions_filepath, allow_pickle=True)\n",
    "captions_dict = captions_dict.item()\n",
    "image_name_list = captions_dict['image_name_list']\n",
    "caption_list    = captions_dict['caption_list']\n",
    "\n",
    "\n",
    "# get LLM responses\n",
    "gpt_response_list = []\n",
    "for indx in range(start_indx, end_indx):\n",
    "\n",
    "\n",
    "    # print(indx)\n",
    "    image_name = image_name_list[indx]\n",
    "    caption = caption_list[indx]\n",
    "    \n",
    "    if caption: # caption is not empty\n",
    "        content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "        print (content_str)\n",
    "        completion = openai.ChatCompletion.create(\n",
    "          #model=\"gpt-3.5-turbo\",\n",
    "          model=\"gpt-4\",\n",
    "          messages=[{\"role\": \"user\", \"content\": content_str}],\n",
    "          temperature = 0.5,\n",
    "          max_tokens=100\n",
    "        )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list.append(response)\n",
    "    print(response)\n",
    "    print('-'*40)\n",
    "    # write the response\n",
    "    response_filepath = os.path.join(response_dir, image_name + '.txt')\n",
    "    with open(response_filepath, \"w\") as text_file:\n",
    "        text_file.write(response)\n",
    "\n",
    "    time.sleep(2)\n",
    "# response_dict = {'image_name_list': image_name_list, 'response_list':gpt_response_list}\n",
    "# np.save(response_filepath, response_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dde1f6-2165-4ddf-be65-217da74e442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_list_100 = gpt_response_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b7df732-d960-41a2-849a-a8d38b8975b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_list_1000 = gpt_response_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "674bc166-f21b-4638-b802-d95528776e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " '9',\n",
       " '8',\n",
       " '8',\n",
       " '10',\n",
       " '7',\n",
       " '1',\n",
       " '5',\n",
       " '7',\n",
       " '8',\n",
       " '7',\n",
       " '10',\n",
       " '7',\n",
       " '5',\n",
       " '4',\n",
       " '8',\n",
       " '8',\n",
       " '5',\n",
       " '8',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '8',\n",
       " '8',\n",
       " '10',\n",
       " '9',\n",
       " '8',\n",
       " '10',\n",
       " '7']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57cbdb96-d832-4914-91af-9eedc05ab8c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n",
      "9 8\n",
      "8 5\n",
      "8 5\n",
      "10 7\n",
      "7 5\n",
      "1 1\n",
      "5 3\n",
      "7 6\n",
      "8 5\n",
      "7 5\n",
      "10 10\n",
      "7 5\n",
      "5 3\n",
      "4 2\n",
      "8 5\n",
      "8 7\n",
      "5 3\n",
      "8 5\n",
      "5 4\n",
      "6 3\n",
      "7 5\n",
      "8 7\n",
      "8 6\n",
      "8 5\n",
      "10 8\n",
      "9 7\n",
      "8 5\n",
      "10 5\n",
      "7 5\n"
     ]
    }
   ],
   "source": [
    "for g3, g4 in zip(gpt4_list, gpt_response_list):\n",
    "    print(g3, g4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96ecc699-e1d4-417e-8b30-8782b48f4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(np.float64(gpt4_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa0433c4-2240-4e16-97ea-a2af69e67c19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6',\n",
       " '10 - This is a very common setup for a living room in many households.',\n",
       " '6. It is a fairly common sight, especially in areas where citrus fruits are grown or in season. However, it may not be as common in areas where these fruits are not readily available or in areas where other types of fruits are more popular.',\n",
       " '8',\n",
       " '10 - extremely common.',\n",
       " '6',\n",
       " '2',\n",
       " '2 - While it is not impossible to see a group of three bears walking through a grassy field, it is not a common occurrence. Bears are generally solitary animals and only come together in groups during mating season or when a mother is caring for her cubs.',\n",
       " '6',\n",
       " '7',\n",
       " '7',\n",
       " '10',\n",
       " '8',\n",
       " '5. It is a somewhat common image, as skiing is a popular activity and arches are a common architectural feature. However, it is not so common that it would be immediately recognizable or iconic.',\n",
       " '2 - While it is possible for a man to be standing next to an elephant wearing a blue hat and blue shirt, it is not a particularly common occurrence.',\n",
       " '6',\n",
       " '8',\n",
       " '3',\n",
       " '8',\n",
       " '7',\n",
       " \"5 - It's not an uncommon image, but it's not extremely common either. It may depend on the context or occasion.\",\n",
       " '8',\n",
       " '8',\n",
       " '7',\n",
       " '7',\n",
       " '8',\n",
       " '8',\n",
       " '7',\n",
       " '8',\n",
       " '8']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e1777-a53d-4b1c-a855-72a5e185d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \" - how common is this in a scale between 0 to 10? The rating is:\"\n",
    "\n",
    "model=\"gpt-4\",\n",
    "messages=[{\"role\": \"user\", \"content\": content_str}],\n",
    "temperature = 0.5,\n",
    "max_tokens=100\n",
    "\n",
    "\"a man standing on a street corner talking on a cell phone\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a horse pulling a small car down a road\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "1\n",
    "----------------------------------------\n",
    "\"a group of people standing around a bunk bed with a ladder\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "3\n",
    "----------------------------------------\n",
    "\"a red car parked on top of a roof next to a house\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "1\n",
    "----------------------------------------\n",
    "\"a plane that is in a cemetery with people walking by\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "1\n",
    "----------------------------------------\n",
    "\"a man walking down a street with a yellow machine on the road\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "4\n",
    "----------------------------------------\n",
    "\"a truck is stuck in a drive thru at a fast food restaurant\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "3\n",
    "----------------------------------------\n",
    "\"a car is in the front of a store that is on fire\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "2\n",
    "----------------------------------------\n",
    "\"a black sports car is upside down in a grassy area\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "3\n",
    "----------------------------------------\n",
    "\"a toilet sitting on top of a mailbox on a street\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "0\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05eff78-508d-46bf-a30e-99e782250706",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \" - how likely is this in a scale between 0 to 10? The rating is:\"\n",
    "\n",
    "model=\"gpt-4\",\n",
    "messages=[{\"role\": \"user\", \"content\": content_str}],\n",
    "temperature = 0.5,\n",
    "max_tokens=100\n",
    "\n",
    "\"a man standing on a street corner talking on a cell phone\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a horse pulling a small car down a road\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "7\n",
    "----------------------------------------\n",
    "\"a group of people standing around a bunk bed with a ladder\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "7\n",
    "----------------------------------------\n",
    "\"a red car parked on top of a roof next to a house\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "3\n",
    "----------------------------------------\n",
    "\"a plane that is in a cemetery with people walking by\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "3\n",
    "----------------------------------------\n",
    "\"a man walking down a street with a yellow machine on the road\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "7\n",
    "----------------------------------------\n",
    "\"a truck is stuck in a drive thru at a fast food restaurant\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "\"a car is in the front of a store that is on fire\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "\"a black sports car is upside down in a grassy area\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "\"a toilet sitting on top of a mailbox on a street\" - how likely is this in a scale between 0 to 10? The rating is:\n",
    "1\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29e113-c5c9-486d-9d27-10b1ae991fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \" - how possible is this in a scale between 0 to 10? The rating is:\"\n",
    "\n",
    "model=\"gpt-4\",\n",
    "messages=[{\"role\": \"user\", \"content\": content_str}],\n",
    "temperature = 0.5,\n",
    "max_tokens=100\n",
    "\n",
    "\"a man standing on a street corner talking on a cell phone\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "10\n",
    "----------------------------------------\n",
    "\"a horse pulling a small car down a road\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a group of people standing around a bunk bed with a ladder\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "10\n",
    "----------------------------------------\n",
    "\"a red car parked on top of a roof next to a house\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "\"a plane that is in a cemetery with people walking by\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "\"a man walking down a street with a yellow machine on the road\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a truck is stuck in a drive thru at a fast food restaurant\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a car is in the front of a store that is on fire\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a black sports car is upside down in a grassy area\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a toilet sitting on top of a mailbox on a street\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "2\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b79844-67d0-48f8-99be-d0ae20c8e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" - how possible is this in a scale between 0 to 10? The rating is:\"\n",
    "model=\"gpt-4\",\n",
    "          messages=[{\"role\": \"user\", \"content\": content_str}],\n",
    "          temperature = 0.5,\n",
    "          max_tokens=1000\n",
    "            \n",
    "\"a man standing on a street corner talking on a cell phone\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "10\n",
    "----------------------------------------\n",
    "\"a horse pulling a small car down a road\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a group of people standing around a bunk bed with a ladder\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a red car parked on top of a roof next to a house\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "\"a plane that is in a cemetery with people walking by\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "\"a man walking down a street with a yellow machine on the road\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a truck is stuck in a drive thru at a fast food restaurant\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a car is in the front of a store that is on fire\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a black sports car is upside down in a grassy area\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a toilet sitting on top of a mailbox on a street\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "2\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b7937-deb8-46ab-a565-78c917e20e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"a man standing on a street corner talking on a cell phone\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "10\n",
    "----------------------------------------\n",
    "\"a horse pulling a small car down a road\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a group of people standing around a bunk bed with a ladder\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "10\n",
    "----------------------------------------\n",
    "\"a red car parked on top of a roof next to a house\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "7\n",
    "----------------------------------------\n",
    "\"a plane that is in a cemetery with people walking by\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "4\n",
    "----------------------------------------\n",
    "\"a man walking down a street with a yellow machine on the road\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a truck is stuck in a drive thru at a fast food restaurant\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "7\n",
    "----------------------------------------\n",
    "\"a car is in the front of a store that is on fire\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a black sports car is upside down in a grassy area\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "\"a toilet sitting on top of a mailbox on a street\" - how possible is this in a scale between 0 to 10? The rating is:\n",
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27a9c0-503a-4558-b806-f500712eefbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "0\n",
    "\"a man on horseback with a flag in front of a crowd\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "1\n",
    "\"a living room with a couch, chair, table and a television\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "8\n",
    "----------------------------------------\n",
    "2\n",
    "\"a pile of oranges and grapefruit sitting on a table\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "3\n",
    "\"a young boy swinging a baseball bat in a field\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "4\n",
    "\"a woman sitting at a table with a plate of food\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "7\n",
    "----------------------------------------\n",
    "5\n",
    "\"a large black and white photo of a building with a sign\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "6\n",
    "\"a man standing in a brick oven with a fire burning\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "1\n",
    "----------------------------------------\n",
    "7\n",
    "\"a group of three bears walking through a grassy field\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "8\n",
    "\"a desk with a laptop and a desktop computer on it\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------\n",
    "9\n",
    "\"two small ponies standing in a field of green grass\" - how common is this in a scale between 0 to 10? The rating is:\n",
    "5\n",
    "----------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
