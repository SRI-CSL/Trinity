{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9d2b241-dd31-413d-81b7-23bf6dab58c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_dir           = \"/WorkSpace-2/aroy/data/datasets/coco_ooc/OOC_images_selected/\"\n",
    "caption_dir       = \"/WorkSpace-2/aroy/data/datasets/coco_ooc/OOC_images_selected_captions/\"\n",
    "captions_filepath = '/WorkSpace-2/aroy/data/OOC/LLM/coco_ooc_captions.npy'\n",
    "\n",
    "os.makedirs(caption_dir, exist_ok=True)\n",
    "\n",
    "# hyperparameters\n",
    "max_new_tokens=20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "782d88f5-5e86-42b2-b353-bee62b9f7e25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2240dc8630482882595b91a1c7c092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 39.44 GiB total capacity; 21.21 GiB already allocated; 31.94 MiB free; 21.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1210437/818327111.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlip2ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Salesforce/blip2-opt-6.7b-coco\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1901\u001b[0m             )\n\u001b[1;32m   1902\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1903\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/aroy/conda/anaconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    924\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 39.44 GiB total capacity; 21.21 GiB already allocated; 31.94 MiB free; 21.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-6.7b-coco\")\n",
    "# by default `from_pretrained` loads the weights in float32\n",
    "# we load in float16 instead to save memory\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16) \n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-6.7b-coco\", torch_dtype=torch.float16) \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f707a5db-fa93-4302-af5d-8c9c88c2b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_path_list = glob.glob(os.path.join(img_dir, '*.jpg'))\n",
    "image_name_list = ['']*len(image_path_list)\n",
    "caption_list    = ['']*len(image_path_list)\n",
    "\n",
    "for indx, image_path in enumerate(image_path_list):\n",
    "    \n",
    "    image_name = os.path.splitext(os.path.split(image_path)[1])[0]\n",
    "    image_name_list[indx] = image_name\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    inputs = processor(image, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()    \n",
    "    caption_list[indx] = caption\n",
    "    \n",
    "captions_dict = {'image_name_list': image_name_list, 'caption_list':caption_list}\n",
    "np.save(captions_filepath, captions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6e56ab-2c6b-41f0-8837-ccfe3a6a38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "455860aa-b2ff-40cf-aa59-6bcd5a4b8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import openai\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = 'opeb_ai_key'\n",
    "\n",
    "captions_filepath = '/WorkSpace-2/aroy/data/OOC/LLM/coco_ooc_captions.npy'\n",
    "captions_dict = np.load(captions_filepath, allow_pickle=True)\n",
    "captions_dict = captions_dict.item()\n",
    "\n",
    "image_name_list = captions_dict['image_name_list']\n",
    "caption_list    = captions_dict['caption_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3edb5591-8cc2-40fa-8cc1-8e3f5d68500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_val2014_000000004296_var1_512_0 : a zebra is standing in a room with a laptop on a table\n",
      "COCO_val2014_000000004296_var1_512_0 : a tennis players are playing a game on a blue court\n",
      "COCO_val2014_000000004296_var1_512_0 : a laptop computer sitting on a desk with a giraffe on it\n",
      "COCO_val2014_000000004296_var1_512_0 : two men riding horses on the beach with a suitcase in the background\n",
      "COCO_val2014_000000004296_var1_512_0 : a large sheep is standing in a living room with a table and chairs\n",
      "COCO_val2014_000000004296_var1_512_0 : a baseball game with a slice of pizza on the field\n",
      "COCO_val2014_000000004296_var1_512_0 : a baseball game with a batter, catcher, umpire and pitcher\n",
      "COCO_val2014_000000004296_var1_512_0 : a bird sitting on top of a kitchen counter in a remodeled kitchen\n"
     ]
    }
   ],
   "source": [
    "for img_name, caption in zip(image_name_list, caption_list):\n",
    "    print(image_name + ' : ' + caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe419fee-f405-47d6-95a6-65ba8612278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_string = \" - is this normal?\"\n",
    "gpt_response_list = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list[indx] = response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2f1f13-0809-4573-bebc-d0afc85e132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_string = \" - is this normal? yes or no\"\n",
    "gpt_response_list_YN = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list_YN[indx] = response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1bf6bc6-1b01-4c36-b5da-eecc26bc15e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no',\n",
       " 'Yes, it is normal for tennis players to play a game on a court, although not all courts are blue.',\n",
       " 'no',\n",
       " 'No',\n",
       " 'no',\n",
       " 'no',\n",
       " 'Yes',\n",
       " 'no']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_response_list_YN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9392277-15ec-43ca-93d3-d354cbe8f32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is not normal for a zebra to be standing in a room with a laptop on a table. The percentage of possibility is extremely low, probably less than 1%. Zebras are wild animals typically found in grasslands and savannas, not in human environments like rooms with technology.\\n',\n",
       " \"Yes, it is normal for tennis players to play a game on a blue court. Blue courts are quite common, particularly in hard court surfaces, such as those used in the Australian Open and the US Open. It's difficult to assign an exact percentage of possibility, but it is certainly a common occurrence in the world of tennis.\",\n",
       " \"It is not normal to see a laptop computer sitting on a desk with a giraffe on it. This could be interpreted as a small toy or figurine of a giraffe, which would be more plausible. However, if it's meant to be a real-life giraffe, that would be highly improbable. \\n\\nIn the case of a small toy or figurine: 75%\\nIn the case of a real-life giraffe: <1%\",\n",
       " \"It is not common to see two men riding horses on the beach with a suitcase in the background, but it's not impossible. The percentage of possibility is subjective and could vary based on location, culture, and personal experiences. In general, I would estimate a low percentage of possibility, maybe around 5-10%.\",\n",
       " \"It is not normal for a large sheep to be standing in a living room with a table and chairs. While it's difficult to assign an exact percentage to the possibility, it would be considered highly unlikely and out of the ordinary, so less than 1% possibility.\",\n",
       " 'No, it is not normal to have a slice of pizza on the field during a baseball game. The percentage of possibility is likely less than 1%, as it is highly unusual and against the rules to have foreign objects on the playing field during a game.',\n",
       " 'Yes, this is a normal scenario in a baseball game. The batter, catcher, umpire, and pitcher are all essential roles in the game. The percentage of possibility for this scenario to occur is close to 100% during a typical baseball game.',\n",
       " 'It is not normal for a bird to be sitting on top of a kitchen counter in a remodeled kitchen, as birds are generally not found inside homes, especially on kitchen counters. The percentage of possibility for this occurrence is relatively low, perhaps around 5-10%, depending on factors such as open windows or doors, the presence of pet birds, or if the house is located in an area with a high bird population.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = \" - is this normal? percentage of possibility\"\n",
    "gpt_response_list = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list[indx] = response\n",
    "    \n",
    "gpt_response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c28da24-850b-4ed2-b30b-69eedbdba6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I would say this is a 1 or 2 on a scale of 0 to 10, as it is highly unlikely but still within the realm of possibility if it were set up intentionally for entertainment or an art installation.',\n",
       " '7',\n",
       " 'I would say it is a 2. While it is possible to have a giraffe figurine or a giraffe sticker on a laptop, having an actual giraffe on a laptop is highly unlikely due to size and weight constraints.',\n",
       " \"I would say a 3, as it's not impossible but rather uncommon to see men riding horses on the beach with a suitcase in the background.\",\n",
       " '3',\n",
       " 'I would say a 2, as it is quite unlikely but not impossible that someone might accidentally drop a slice of pizza on the field.',\n",
       " '10',\n",
       " \"It is difficult to provide a precise number on the likelihood of this, as it depends on a number of factors such as whether the bird is a pet or managed to fly in accidentally, or if the kitchen is open to the outdoors in some way. I would say it's a 4 or 5 out of 10, as it's not completely unlikely but also not very common in most households.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = \" - how likely is this in a scale between 0 to 10\"\n",
    "\n",
    "gpt_response_list = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list[indx] = response\n",
    "    \n",
    "gpt_response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bee2da-4d4a-4f1c-97f3-85ba83508cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \" - whats is the most likely object that is out of context?\"\n",
    "\n",
    "gpt_response_list = ['']*len(caption_list)\n",
    "for indx, caption in enumerate(caption_list):\n",
    "    \n",
    "    content_str = \"\\\"\" + caption + \"\\\"\" + query_string\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": content_str}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_response_list[indx] = response\n",
    "    \n",
    "gpt_response_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
